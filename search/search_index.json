{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#aimet-ml","title":"aimet-ml","text":"<p>Python package of frequently used modules for ML developments in AIMET.</p> <ul> <li>Documentation: https://aimet-tech.github.io/aimet-ml</li> <li>GitHub: https://github.com/aimet-tech/aimet-ml</li> <li>PyPI: https://pypi.org/project/aimet-ml/</li> <li>Free software: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#033---2023-10-30","title":"[0.3.3] - 2023-10-30","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Add trim_tokens for text processing</li> </ul>"},{"location":"changelog/#032---2023-10-27","title":"[0.3.2] - 2023-10-27","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Edit type hints</li> <li>Convert variables to appropriate types</li> </ul>"},{"location":"changelog/#031---2023-10-27","title":"[0.3.1] - 2023-10-27","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>Add docstrings and type hints to the test scripts of the new utility modules.</li> </ul>"},{"location":"changelog/#030---2023-10-26","title":"[0.3.0] - 2023-10-26","text":""},{"location":"changelog/#added_3","title":"Added","text":"<ul> <li>Add utilities for training pipeline.</li> <li>aws utils</li> <li>git utils</li> <li>io utils</li> <li>wandb utils</li> </ul>"},{"location":"changelog/#020---2023-08-28","title":"[0.2.0] - 2023-08-28","text":""},{"location":"changelog/#added_4","title":"Added","text":"<ul> <li>Change layout of module document</li> </ul>"},{"location":"changelog/#011---2023-08-26","title":"[0.1.1] - 2023-08-26","text":""},{"location":"changelog/#added_5","title":"Added","text":"<ul> <li>Cover tests for more modules</li> </ul>"},{"location":"changelog/#010---2023-08-26","title":"[0.1.0] - 2023-08-26","text":""},{"location":"changelog/#added_6","title":"Added","text":"<ul> <li>First release (pre-release) on PyPI.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/aimet-tech/aimet-ml/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>aimet-ml could always use more documentation, whether as part of the official aimet-ml docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/aimet-tech/aimet-ml/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>aimet-ml</code> for local development.</p> <ol> <li>Fork the <code>aimet-ml</code> repo on GitHub.</li> <li> <p>Clone your fork locally</p> <pre><code>$ git clone git@github.com:your_name_here/aimet-ml.git\n</code></pre> </li> <li> <p>Ensure poetry is installed.</p> </li> <li> <p>Install dependencies and start your virtualenv:</p> <pre><code>$ poetry install -E test -E doc -E dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</p> <pre><code>$ poetry run tox\n</code></pre> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python 3.9. Check    https://github.com/aimet-tech/aimet-ml/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<pre><code>$ poetry run pytest tests/test_aimet_ml.py\n</code></pre> <p>To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run:</p> <pre><code>$ poetry run bump2version patch # possible: major / minor / patch\n$ git push\n$ git push --tags\n</code></pre> <p>GitHub Actions will then deploy to PyPI if tests pass.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install aimet-ml, run this command in your terminal:</p> <pre><code>$ pip install aimet-ml\n</code></pre> <p>This is the preferred method to install aimet-ml, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for aimet-ml can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>$ git clone git://github.com/aimet-tech/aimet-ml\n</code></pre> <p>Or download the tarball:</p> <pre><code>$ curl -OJL https://github.com/aimet-tech/aimet-ml/tarball/main\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>$ pip install .\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage","title":"Usage","text":"<p>To use aimet-ml in a project</p> <pre><code>import aimet_ml\n</code></pre>"},{"location":"api/features/","title":"features","text":""},{"location":"api/features/#aimet_ml.features.textual","title":"<code>textual</code>","text":""},{"location":"api/features/#aimet_ml.features.textual.transformers","title":"<code>transformers</code>","text":""},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor","title":"<code>TransformerFeatureExtractor</code>","text":"<p>Extracts features from input texts using transformer embeddings.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>class TransformerFeatureExtractor:\n    \"\"\"Extracts features from input texts using transformer embeddings.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str,\n        num_emb_layers: int = 4,\n        max_length: int = 512,\n        device: Union[str, torch.device] = \"cuda:0\",\n    ):\n        \"\"\"\n        Initializes the TransformerFeatureExtractor.\n\n        Args:\n            model_name (str): The name or path of the pre-trained transformer model.\n            num_emb_layers (int, optional): Number of layers to use for feature extraction. Default is 4.\n            max_length (int, optional): Maximum length of input text for tokenization. Default is 512.\n            device (str or torch.device, optional): Device to use for computation ('cuda:0', 'cpu', etc.).\n                Default is 'cuda:0' if available, else 'cpu'.\n        \"\"\"\n\n        if not torch.cuda.is_available():\n            device = \"cpu\"\n\n        self.model = AutoModel.from_pretrained(model_name)\n        self.model.to(device)\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.num_emb_layers = num_emb_layers\n        self.max_length = max_length\n\n    def extract_features(self, texts: Union[str, List[str]]) -&gt; torch.Tensor:\n        \"\"\"\n        Extracts features from input texts using transformer embeddings.\n\n        Args:\n            texts (str or list): Input text or list of texts for feature extraction.\n\n        Returns:\n            torch.Tensor: Extracted features for input texts.\n        \"\"\"\n        self.model.eval()\n\n        if isinstance(texts, str):\n            texts = [texts]\n\n        input_ids, attention_masks = [], []\n        for text in texts:\n            tokenized_output = self.tokenize(text)\n            input_ids.append(tokenized_output[\"input_ids\"])\n            attention_masks.append(tokenized_output[\"attention_mask\"])\n        input_ids_tensor = torch.cat(input_ids, dim=0).to(self.model.device)\n        attention_masks_tensor = torch.cat(attention_masks, dim=0).to(self.model.device)\n\n        with torch.no_grad():\n            hidden_states = self.model(\n                input_ids_tensor, attention_mask=attention_masks_tensor, output_hidden_states=True\n            )[\"hidden_states\"]\n\n        embeddings = sum(hidden_states[-i][:, 0, :] for i in range(1, self.num_emb_layers + 1))\n        embeddings = embeddings.detach().cpu()\n\n        return embeddings\n\n    def tokenize(self, text: str) -&gt; dict:\n        \"\"\"\n        Tokenizes input text using the transformer's tokenizer.\n\n        Args:\n            text (str): Input text to be tokenized.\n\n        Returns:\n            dict: Dictionary containing tokenized input with attention mask.\n        \"\"\"\n        tokenized_output = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n\n        return tokenized_output.data\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.__init__","title":"<code>__init__(model_name, num_emb_layers=4, max_length=512, device='cuda:0')</code>","text":"<p>Initializes the TransformerFeatureExtractor.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name or path of the pre-trained transformer model.</p> required <code>num_emb_layers</code> <code>int</code> <p>Number of layers to use for feature extraction. Default is 4.</p> <code>4</code> <code>max_length</code> <code>int</code> <p>Maximum length of input text for tokenization. Default is 512.</p> <code>512</code> <code>device</code> <code>str or device</code> <p>Device to use for computation ('cuda:0', 'cpu', etc.). Default is 'cuda:0' if available, else 'cpu'.</p> <code>'cuda:0'</code> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def __init__(\n    self,\n    model_name: str,\n    num_emb_layers: int = 4,\n    max_length: int = 512,\n    device: Union[str, torch.device] = \"cuda:0\",\n):\n    \"\"\"\n    Initializes the TransformerFeatureExtractor.\n\n    Args:\n        model_name (str): The name or path of the pre-trained transformer model.\n        num_emb_layers (int, optional): Number of layers to use for feature extraction. Default is 4.\n        max_length (int, optional): Maximum length of input text for tokenization. Default is 512.\n        device (str or torch.device, optional): Device to use for computation ('cuda:0', 'cpu', etc.).\n            Default is 'cuda:0' if available, else 'cpu'.\n    \"\"\"\n\n    if not torch.cuda.is_available():\n        device = \"cpu\"\n\n    self.model = AutoModel.from_pretrained(model_name)\n    self.model.to(device)\n\n    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n    self.num_emb_layers = num_emb_layers\n    self.max_length = max_length\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.extract_features","title":"<code>extract_features(texts)</code>","text":"<p>Extracts features from input texts using transformer embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>str or list</code> <p>Input text or list of texts for feature extraction.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Extracted features for input texts.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def extract_features(self, texts: Union[str, List[str]]) -&gt; torch.Tensor:\n    \"\"\"\n    Extracts features from input texts using transformer embeddings.\n\n    Args:\n        texts (str or list): Input text or list of texts for feature extraction.\n\n    Returns:\n        torch.Tensor: Extracted features for input texts.\n    \"\"\"\n    self.model.eval()\n\n    if isinstance(texts, str):\n        texts = [texts]\n\n    input_ids, attention_masks = [], []\n    for text in texts:\n        tokenized_output = self.tokenize(text)\n        input_ids.append(tokenized_output[\"input_ids\"])\n        attention_masks.append(tokenized_output[\"attention_mask\"])\n    input_ids_tensor = torch.cat(input_ids, dim=0).to(self.model.device)\n    attention_masks_tensor = torch.cat(attention_masks, dim=0).to(self.model.device)\n\n    with torch.no_grad():\n        hidden_states = self.model(\n            input_ids_tensor, attention_mask=attention_masks_tensor, output_hidden_states=True\n        )[\"hidden_states\"]\n\n    embeddings = sum(hidden_states[-i][:, 0, :] for i in range(1, self.num_emb_layers + 1))\n    embeddings = embeddings.detach().cpu()\n\n    return embeddings\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.tokenize","title":"<code>tokenize(text)</code>","text":"<p>Tokenizes input text using the transformer's tokenizer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to be tokenized.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing tokenized input with attention mask.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def tokenize(self, text: str) -&gt; dict:\n    \"\"\"\n    Tokenizes input text using the transformer's tokenizer.\n\n    Args:\n        text (str): Input text to be tokenized.\n\n    Returns:\n        dict: Dictionary containing tokenized input with attention mask.\n    \"\"\"\n    tokenized_output = self.tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=self.max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors=\"pt\",\n    )\n\n    return tokenized_output.data\n</code></pre>"},{"location":"api/processing/","title":"processing","text":""},{"location":"api/processing/#aimet_ml.processing.audio","title":"<code>audio</code>","text":""},{"location":"api/processing/#aimet_ml.processing.audio.convert_audio","title":"<code>convert_audio(src_file, dst_file, target_sr=None, normalize=False)</code>","text":"<p>Convert an audio file to a different sample rate and save it to a new file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>str</code> <p>Path to the source audio file.</p> required <code>dst_file</code> <code>str</code> <p>Path to the destination audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the output audio file.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform before conversion.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>AudioSegment</code> <code>AudioSegment</code> <p>The converted audio waveform as an AudioSegment object.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def convert_audio(\n    src_file: str, dst_file: str, target_sr: Optional[int] = None, normalize: bool = False\n) -&gt; AudioSegment:\n    \"\"\"\n    Convert an audio file to a different sample rate and save it to a new file.\n\n    Args:\n        src_file (str): Path to the source audio file.\n        dst_file (str): Path to the destination audio file.\n        target_sr (int, optional): Target sample rate for the output audio file.\n        normalize (bool, optional): If True, normalize the audio waveform before conversion.\n\n    Returns:\n        AudioSegment: The converted audio waveform as an AudioSegment object.\n    \"\"\"\n    audio = read_audio(src_file, target_sr, normalize)\n    output_format = dst_file.split(\".\")[-1]\n    audio.export(dst_file, format=output_format)\n    return audio\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.audio.load_audio","title":"<code>load_audio(file_path, target_sr=None, normalize=False)</code>","text":"<p>Load an audio file and return the waveform as a NumPy array and the target sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the audio waveform.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, int]</code> <p>Tuple[np.ndarray, int]: A tuple containing the waveform as a NumPy array and the target sample rate.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def load_audio(file_path: str, target_sr: Optional[int] = None, normalize: bool = False) -&gt; Tuple[np.ndarray, int]:\n    \"\"\"\n    Load an audio file and return the waveform as a NumPy array and the target sample rate.\n\n    Args:\n        file_path (str): Path to the audio file.\n        target_sr (int, optional): Target sample rate for the audio waveform.\n        normalize (bool, optional): If True, normalize the audio waveform.\n\n    Returns:\n        Tuple[np.ndarray, int]: A tuple containing the waveform as a NumPy array and the target sample rate.\n    \"\"\"\n    audio = read_audio(file_path, target_sr, normalize)\n    waveform = np.asarray(audio.get_array_of_samples(), dtype=np.float32) / 32768.0\n    sample_rate = audio.frame_rate\n    return waveform, sample_rate\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.audio.read_audio","title":"<code>read_audio(file_path, target_sr=None, normalize=False)</code>","text":"<p>Read an audio file and return the waveform as an AudioSegment object with the target sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the audio waveform.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>AudioSegment</code> <code>AudioSegment</code> <p>Audio waveform as an AudioSegment object.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def read_audio(file_path: str, target_sr: Optional[int] = None, normalize: bool = False) -&gt; AudioSegment:\n    \"\"\"\n    Read an audio file and return the waveform as an AudioSegment object with the target sample rate.\n\n    Args:\n        file_path (str): Path to the audio file.\n        target_sr (int, optional): Target sample rate for the audio waveform.\n        normalize (bool, optional): If True, normalize the audio waveform.\n\n    Returns:\n        AudioSegment: Audio waveform as an AudioSegment object.\n    \"\"\"\n    audio = AudioSegment.from_file(file_path)\n    if target_sr:\n        audio = audio.set_frame_rate(target_sr)\n    if normalize:\n        audio = effects.normalize(audio)\n    return audio\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text","title":"<code>text</code>","text":""},{"location":"api/processing/#aimet_ml.processing.text.clean_repeated_tokens","title":"<code>clean_repeated_tokens(tokens)</code>","text":"<p>Remove sequences of repeated tokens from a list.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[str]</code> <p>List of tokens to clean.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>list[str]: List of tokens with repeated sequences removed.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def clean_repeated_tokens(tokens: List[str]) -&gt; List[str]:\n    \"\"\"\n    Remove sequences of repeated tokens from a list.\n\n    Args:\n        tokens (list[str]): List of tokens to clean.\n\n    Returns:\n        list[str]: List of tokens with repeated sequences removed.\n    \"\"\"\n    tokens = tokens.copy()\n    sequence_size = len(tokens) // 2\n    while sequence_size &gt; 0:\n        cur_idx = 0\n        while cur_idx &lt; len(tokens) - sequence_size:\n            next_idx = cur_idx + sequence_size\n            cur_text = \"\".join(tokens[cur_idx : cur_idx + sequence_size])\n            next_text = \"\".join(tokens[next_idx : next_idx + sequence_size])\n            if cur_text == next_text:\n                tokens = tokens[: cur_idx + sequence_size] + tokens[next_idx + sequence_size :]\n            else:\n                cur_idx += 1\n        sequence_size -= 1\n    return tokens\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text.exclude_keywords","title":"<code>exclude_keywords(text, keywords)</code>","text":"<p>Check if any of the given keywords are present in the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to search for keywords.</p> required <code>keywords</code> <code>list[str]</code> <p>List of keywords to check for.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>False if any keyword is present in the text, True otherwise.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def exclude_keywords(text: str, keywords: List[str]) -&gt; bool:\n    \"\"\"\n    Check if any of the given keywords are present in the text.\n\n    Args:\n        text (str): The text to search for keywords.\n        keywords (list[str]): List of keywords to check for.\n\n    Returns:\n        bool: False if any keyword is present in the text, True otherwise.\n    \"\"\"\n    for kw in keywords:\n        if kw in text:\n            return False\n    return True\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text.include_keywords","title":"<code>include_keywords(text, keywords)</code>","text":"<p>Check if any of the given keywords are present in the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to search for keywords.</p> required <code>keywords</code> <code>list[str]</code> <p>List of keywords to check for.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any keyword is present in the text, False otherwise.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def include_keywords(text: str, keywords: List[str]) -&gt; bool:\n    \"\"\"\n    Check if any of the given keywords are present in the text.\n\n    Args:\n        text (str): The text to search for keywords.\n        keywords (list[str]): List of keywords to check for.\n\n    Returns:\n        bool: True if any keyword is present in the text, False otherwise.\n    \"\"\"\n    for kw in keywords:\n        if kw in text:\n            return True\n    return False\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text.trim_tokens","title":"<code>trim_tokens(tokenizer, text, max_len)</code>","text":"<p>Trims a list of tokens generated by a tokenizer to ensure it doesn't exceed a maximum length.</p> <p>Parameters:</p> Name Type Description Default <code>tokenizer</code> <code>PreTrainedTokenizer</code> <p>The tokenizer used to tokenize the input text.</p> required <code>text</code> <code>str</code> <p>The input text to tokenize and trim.</p> required <code>max_len</code> <code>int</code> <p>The maximum allowed length for the list of tokens.</p> required <p>Returns:</p> Type Description <code>Tuple[str, int]</code> <p>Tuple[str, int]: A tuple containing the trimmed text and the number of tokens in the trimmed list.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def trim_tokens(tokenizer: PreTrainedTokenizer, text: str, max_len: int) -&gt; Tuple[str, int]:\n    \"\"\"\n    Trims a list of tokens generated by a tokenizer to ensure it doesn't exceed a maximum length.\n\n    Args:\n        tokenizer (PreTrainedTokenizer): The tokenizer used to tokenize the input text.\n        text (str): The input text to tokenize and trim.\n        max_len (int): The maximum allowed length for the list of tokens.\n\n    Returns:\n        Tuple[str, int]: A tuple containing the trimmed text and the number of tokens in the trimmed list.\n    \"\"\"\n    tokens = tokenizer.tokenize(text)\n\n    if len(tokens) &gt; max_len:\n        tokens = tokens[:max_len]\n\n    return tokenizer.convert_tokens_to_string(tokens), len(tokens)\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video","title":"<code>video</code>","text":""},{"location":"api/processing/#aimet_ml.processing.video.convert_video","title":"<code>convert_video(src_file, dst_file, target_fps)</code>","text":"<p>Convert a video to a different frame rate and save to a new file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>str</code> <p>Path to the source video file.</p> required <code>dst_file</code> <code>str</code> <p>Path to the output video file.</p> required <code>target_fps</code> <code>int</code> <p>The target frames per second for the output video.</p> required Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def convert_video(src_file: str, dst_file: str, target_fps: int) -&gt; None:\n    \"\"\"\n    Convert a video to a different frame rate and save to a new file.\n\n    Args:\n        src_file (str): Path to the source video file.\n        dst_file (str): Path to the output video file.\n        target_fps (int): The target frames per second for the output video.\n    \"\"\"\n    input_vid = ffmpeg.input(src_file)\n\n    audio = input_vid.audio\n    video = input_vid.video.filter(\"fps\", target_fps)\n    (\n        ffmpeg.output(\n            video,\n            audio,\n            dst_file,\n            acodec=\"aac\",\n            loglevel=\"quiet\",\n            max_muxing_queue_size=1024,\n        )\n        .overwrite_output()\n        .run()\n    )\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video.is_video","title":"<code>is_video(file_path)</code>","text":"<p>Check if a given file contains video streams.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the input file.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file contains video streams, False otherwise.</p> Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def is_video(file_path: str) -&gt; bool:\n    \"\"\"\n    Check if a given file contains video streams.\n\n    Args:\n        file_path (str): The path to the input file.\n\n    Returns:\n        bool: True if the file contains video streams, False otherwise.\n    \"\"\"\n    probe = ffmpeg.probe(file_path)\n    streams = probe[\"streams\"]\n\n    for stream in streams:\n        if stream[\"codec_type\"] == \"video\":\n            return True\n\n    return False\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video.load_video","title":"<code>load_video(file_path)</code>","text":"<p>Load frames from a video file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the video file.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing a list of frames and the frames per second (fps).</p> Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def load_video(file_path: str) -&gt; tuple:\n    \"\"\"\n    Load frames from a video file.\n\n    Args:\n        file_path (str): The path to the video file.\n\n    Returns:\n        tuple: A tuple containing a list of frames and the frames per second (fps).\n    \"\"\"\n    frames: List[np.ndarray] = []\n    cap = cv2.VideoCapture(file_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n\n    cap.release()\n    return frames, fps\n</code></pre>"},{"location":"api/utils/","title":"utils","text":""},{"location":"api/utils/#aimet_ml.utils.aws","title":"<code>aws</code>","text":""},{"location":"api/utils/#aimet_ml.utils.aws.download_s3","title":"<code>download_s3(bucket_name, object_name, output_path)</code>","text":"<p>Download a file from an S3 bucket and save it to the local file system.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the S3 bucket.</p> required <code>object_name</code> <code>str</code> <p>The key or path of the object to be downloaded from the bucket.</p> required <code>output_path</code> <code>str</code> <p>The local file path to save the downloaded object.</p> required Source code in <code>aimet_ml/utils/aws.py</code> <pre><code>def download_s3(bucket_name: str, object_name: str, output_path: str):\n    \"\"\"\n    Download a file from an S3 bucket and save it to the local file system.\n\n    Args:\n        bucket_name (str): The name of the S3 bucket.\n        object_name (str): The key or path of the object to be downloaded from the bucket.\n        output_path (str): The local file path to save the downloaded object.\n    \"\"\"\n    s3 = boto3.client(\"s3\")\n    s3.download_file(bucket_name, object_name, output_path)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.aws.upload_dir_s3","title":"<code>upload_dir_s3(bucket_name, bucket_dir_path, src_dir_path)</code>","text":"<p>Upload a local directory to an S3 bucket, preserving the directory structure.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the S3 bucket.</p> required <code>bucket_dir_path</code> <code>str</code> <p>The path within the bucket where the local directory will be uploaded.</p> required <code>src_dir_path</code> <code>str</code> <p>The local directory path to be uploaded.</p> required Source code in <code>aimet_ml/utils/aws.py</code> <pre><code>def upload_dir_s3(bucket_name: str, bucket_dir_path: str, src_dir_path: str):\n    \"\"\"\n    Upload a local directory to an S3 bucket, preserving the directory structure.\n\n    Args:\n        bucket_name (str): The name of the S3 bucket.\n        bucket_dir_path (str): The path within the bucket where the local directory will be uploaded.\n        src_dir_path (str): The local directory path to be uploaded.\n    \"\"\"\n    s3 = boto3.client(\"s3\")\n    src_dir_name = os.path.basename(src_dir_path)\n    for r, _, f in tqdm(os.walk(src_dir_path)):\n        for n in f:\n            file_path = os.path.join(r, n)\n            relpath = os.path.relpath(r, src_dir_path)\n            object_name = os.path.join(bucket_dir_path, src_dir_name, \"\" if relpath == \".\" else relpath, n)\n            s3.upload_file(file_path, bucket_name, object_name)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.aws.upload_files_s3","title":"<code>upload_files_s3(bucket_name, bucket_dir_path, src_file_paths)</code>","text":"<p>Upload multiple local files to an S3 bucket.</p> <p>Parameters:</p> Name Type Description Default <code>bucket_name</code> <code>str</code> <p>The name of the S3 bucket.</p> required <code>bucket_dir_path</code> <code>str</code> <p>The path within the bucket where the files will be uploaded.</p> required <code>src_file_paths</code> <code>list</code> <p>A list of local file paths to be uploaded to the bucket.</p> required Source code in <code>aimet_ml/utils/aws.py</code> <pre><code>def upload_files_s3(bucket_name: str, bucket_dir_path: str, src_file_paths: list):\n    \"\"\"\n    Upload multiple local files to an S3 bucket.\n\n    Args:\n        bucket_name (str): The name of the S3 bucket.\n        bucket_dir_path (str): The path within the bucket where the files will be uploaded.\n        src_file_paths (list): A list of local file paths to be uploaded to the bucket.\n    \"\"\"\n    s3 = boto3.client(\"s3\")\n    for file_path in tqdm(src_file_paths):\n        object_name = os.path.join(bucket_dir_path, os.path.basename(file_path))\n        s3.upload_file(file_path, bucket_name, object_name)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.git","title":"<code>git</code>","text":""},{"location":"api/utils/#aimet_ml.utils.git.get_commit_id","title":"<code>get_commit_id(short=True)</code>","text":"<p>Get the Git commit ID of the current repository.</p> <p>Parameters:</p> Name Type Description Default <code>short</code> <code>bool</code> <p>Whether to get a short or full Git commit ID. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The Git commit ID as a string.</p> Source code in <code>aimet_ml/utils/git.py</code> <pre><code>def get_commit_id(short: bool = True) -&gt; str:\n    \"\"\"\n    Get the Git commit ID of the current repository.\n\n    Args:\n        short (bool, optional): Whether to get a short or full Git commit ID. Defaults to True.\n\n    Returns:\n        str: The Git commit ID as a string.\n    \"\"\"\n    if short:\n        git_command = \"git rev-parse --short HEAD\"\n    else:\n        git_command = \"git rev-parse HEAD\"\n\n    commit_id = os.popen(git_command).read().strip()\n\n    return commit_id\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.hamd_7","title":"<code>hamd_7</code>","text":""},{"location":"api/utils/#aimet_ml.utils.hamd_7.score_to_severity","title":"<code>score_to_severity(score)</code>","text":"<p>Convert a score to a severity category.</p> <p>Parameters:</p> Name Type Description Default <code>score</code> <code>int</code> <p>The input score.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The corresponding severity category (\"normal\", \"mild\", \"moderate\", or \"severe\").</p> Source code in <code>aimet_ml/utils/hamd_7.py</code> <pre><code>def score_to_severity(score: int) -&gt; str:\n    \"\"\"\n    Convert a score to a severity category.\n\n    Args:\n        score (int): The input score.\n\n    Returns:\n        str: The corresponding severity category (\"normal\", \"mild\", \"moderate\", or \"severe\").\n    \"\"\"\n    if score &lt; 5:\n        return \"normal\"\n    if score &lt; 13:\n        return \"mild\"\n    if score &lt; 21:\n        return \"moderate\"\n    return \"severe\"\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils","title":"<code>io_utils</code>","text":""},{"location":"api/utils/#aimet_ml.utils.io_utils.read_json","title":"<code>read_json(file_path)</code>","text":"<p>Read and parse a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the JSON file to be read.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the parsed JSON data.</p> Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def read_json(file_path: str) -&gt; dict:\n    \"\"\"\n    Read and parse a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file to be read.\n\n    Returns:\n        dict: A dictionary containing the parsed JSON data.\n    \"\"\"\n    with open(file_path, \"r\") as f:\n        data = json.load(f)\n    return data\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils.read_pickle","title":"<code>read_pickle(file_path)</code>","text":"<p>Read and unpickle a binary pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the pickle file to be read.</p> required <p>Returns:</p> Name Type Description <code>Any</code> <p>The unpickled object.</p> Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def read_pickle(file_path: str):\n    \"\"\"\n    Read and unpickle a binary pickle file.\n\n    Args:\n        file_path (str): The path to the pickle file to be read.\n\n    Returns:\n        Any: The unpickled object.\n    \"\"\"\n    with open(file_path, \"rb\") as f:\n        data = pickle.load(f)\n    return data\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils.read_yaml","title":"<code>read_yaml(file_path)</code>","text":"<p>Read and parse a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the YAML file to be read.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the parsed YAML data.</p> Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def read_yaml(file_path: str) -&gt; dict:\n    \"\"\"\n    Read and parse a YAML file.\n\n    Args:\n        file_path (str): The path to the YAML file to be read.\n\n    Returns:\n        dict: A dictionary containing the parsed YAML data.\n    \"\"\"\n    with open(file_path, \"r\") as f:\n        result = yaml.safe_load(f)\n    return result\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils.write_json","title":"<code>write_json(file_path, data, indent=None)</code>","text":"<p>Write data to a JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the JSON file to be written.</p> required <code>data</code> <code>dict</code> <p>The data to be written to the JSON file.</p> required <code>indent</code> <code>int</code> <p>The number of spaces to use for indentation.</p> <code>None</code> Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def write_json(file_path: str, data: dict, indent: Optional[int] = None):\n    \"\"\"\n    Write data to a JSON file.\n\n    Args:\n        file_path (str): The path to the JSON file to be written.\n        data (dict): The data to be written to the JSON file.\n        indent (int, optional): The number of spaces to use for indentation.\n    \"\"\"\n    with open(file_path, \"w\") as f:\n        json.dump(data, f, indent=indent)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils.write_pickle","title":"<code>write_pickle(file_path, data)</code>","text":"<p>Write data to a binary pickle file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the pickle file to be written.</p> required <code>data</code> <p>The data to be pickled and written to the file.</p> required Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def write_pickle(file_path: str, data):\n    \"\"\"\n    Write data to a binary pickle file.\n\n    Args:\n        file_path (str): The path to the pickle file to be written.\n        data: The data to be pickled and written to the file.\n    \"\"\"\n    with open(file_path, \"wb\") as f:\n        pickle.dump(data, f)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.io_utils.write_yaml","title":"<code>write_yaml(file_path, data, default_flow_style=False)</code>","text":"<p>Write data to a YAML file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the YAML file to be written.</p> required <code>data</code> <code>dict</code> <p>The data to be written to the YAML file.</p> required <code>default_flow_style</code> <code>bool</code> <p>Whether to use the default flow style for YAML.</p> <code>False</code> Source code in <code>aimet_ml/utils/io_utils.py</code> <pre><code>def write_yaml(file_path: str, data: dict, default_flow_style: bool = False):\n    \"\"\"\n    Write data to a YAML file.\n\n    Args:\n        file_path (str): The path to the YAML file to be written.\n        data (dict): The data to be written to the YAML file.\n        default_flow_style (bool, optional): Whether to use the default flow style for YAML.\n    \"\"\"\n    with open(file_path, \"w\") as f:\n        yaml.dump(data, f, default_flow_style=default_flow_style)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots","title":"<code>plots</code>","text":""},{"location":"api/utils/#aimet_ml.utils.plots.add_bar_label","title":"<code>add_bar_label(bar_chart, with_percent=False, percent_digits=2)</code>","text":"<p>Add labels to a bar chart with optional percentage values.</p> <p>Parameters:</p> Name Type Description Default <code>bar_chart</code> <code>Axes</code> <p>The bar chart object.</p> required <code>with_percent</code> <code>bool</code> <p>Whether to include percentage values. Defaults to False.</p> <code>False</code> <code>percent_digits</code> <code>int</code> <p>Number of decimal digits for percentage values. Defaults to 2.</p> <code>2</code> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def add_bar_label(bar_chart: plt.Axes, with_percent: bool = False, percent_digits: int = 2) -&gt; None:\n    \"\"\"\n    Add labels to a bar chart with optional percentage values.\n\n    Args:\n        bar_chart (plt.Axes): The bar chart object.\n        with_percent (bool, optional): Whether to include percentage values. Defaults to False.\n        percent_digits (int, optional): Number of decimal digits for percentage values. Defaults to 2.\n    \"\"\"\n    containers = bar_chart.containers[0]\n    labels = None\n    if with_percent:\n        datavalues = containers.datavalues\n        total = sum(datavalues)\n        labels = [f\"{v:,} ({v/total*100:.{percent_digits}f}%)\" for v in datavalues]\n    bar_chart.bar_label(containers, labels)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.plt2arr","title":"<code>plt2arr(fig, draw=True)</code>","text":"<p>Convert a Matplotlib figure to a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>The Matplotlib figure to be converted.</p> required <code>draw</code> <code>bool</code> <p>Whether to draw the figure. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The converted figure as a NumPy array.</p> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def plt2arr(fig: Figure, draw: bool = True) -&gt; np.ndarray:\n    \"\"\"\n    Convert a Matplotlib figure to a NumPy array.\n\n    Args:\n        fig (Figure): The Matplotlib figure to be converted.\n        draw (bool, optional): Whether to draw the figure. Defaults to True.\n\n    Returns:\n        np.ndarray: The converted figure as a NumPy array.\n    \"\"\"\n    if draw:\n        fig.canvas.draw()\n    rgba_buf = fig.canvas.buffer_rgba()\n    (w, h) = fig.canvas.get_width_height()\n    rgba_arr = np.frombuffer(rgba_buf, dtype=np.uint8).reshape((h, w, 4))\n    return rgba_arr\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.set_font","title":"<code>set_font(font_path)</code>","text":"<p>Set the font for Matplotlib using the provided font file.</p> <p>Parameters:</p> Name Type Description Default <code>font_path</code> <code>str</code> <p>Path to the font file.</p> required Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def set_font(font_path: str) -&gt; None:\n    \"\"\"\n    Set the font for Matplotlib using the provided font file.\n\n    Args:\n        font_path (str): Path to the font file.\n    \"\"\"\n    import matplotlib\n    import matplotlib.font_manager\n\n    font_prop = matplotlib.font_manager.FontProperties(fname=font_path)\n    matplotlib.font_manager.fontManager.addfont(font_path)\n    matplotlib.rc(\"font\", family=font_prop.get_name())\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.set_thai_font","title":"<code>set_thai_font()</code>","text":"<p>Set the Thai font for Matplotlib using a predefined font path.</p> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def set_thai_font() -&gt; None:\n    \"\"\"Set the Thai font for Matplotlib using a predefined font path.\"\"\"\n    font_path = str(PWD.parent / \"resources\" / \"fonts\" / \"thsarabunnew-webfont.ttf\")\n    set_font(font_path)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.wandb_utils","title":"<code>wandb_utils</code>","text":""},{"location":"api/utils/#aimet_ml.utils.wandb_utils.list_artifact_names","title":"<code>list_artifact_names(api, artifact_type, with_versions=True, with_aliases=True, per_page=100)</code>","text":"<p>List available artifact names for a specific artifact type.</p> <p>Parameters:</p> Name Type Description Default <code>api</code> <code>Api</code> <p>The WandB API client.</p> required <code>artifact_type</code> <code>str</code> <p>The type of artifact for which names are listed.</p> required <code>with_versions</code> <code>bool</code> <p>Include version suffixes. Defaults to True.</p> <code>True</code> <code>with_aliases</code> <code>bool</code> <p>Include artifact aliases. Defaults to True.</p> <code>True</code> <code>per_page</code> <code>int</code> <p>Number of items to retrieve per page. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A sorted list of available artifact names with optional suffixes (versions or aliases).</p> Source code in <code>aimet_ml/utils/wandb_utils.py</code> <pre><code>def list_artifact_names(\n    api: wandb.Api, artifact_type: str, with_versions: bool = True, with_aliases: bool = True, per_page: int = 100\n) -&gt; list:\n    \"\"\"\n    List available artifact names for a specific artifact type.\n\n    Args:\n        api (wandb.Api): The WandB API client.\n        artifact_type (str): The type of artifact for which names are listed.\n        with_versions (bool, optional): Include version suffixes. Defaults to True.\n        with_aliases (bool, optional): Include artifact aliases. Defaults to True.\n        per_page (int, optional): Number of items to retrieve per page. Defaults to 100.\n\n    Returns:\n        list: A sorted list of available artifact names with optional suffixes (versions or aliases).\n    \"\"\"\n    available_artifact_names = set()\n\n    for collection in api.artifact_type(artifact_type).collections():\n        suffixes = set()\n\n        if with_aliases:\n            suffixes.update(collection.aliases)\n\n        if with_versions:\n            suffixes.update([v.version for v in collection.versions(per_page=per_page)])\n\n        if suffixes:\n            available_artifact_names.update([f\"{collection.name}:{suffix}\" for suffix in suffixes])\n        else:\n            available_artifact_names.update([collection.name])\n\n    return sorted(available_artifact_names)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.wandb_utils.load_artifact","title":"<code>load_artifact(api, artifact_type, artifact_name, artifact_alias, per_page=100)</code>","text":"<p>Load a WandB artifact by name and alias.</p> <p>Parameters:</p> Name Type Description Default <code>api</code> <code>Api</code> <p>The WandB API client.</p> required <code>artifact_type</code> <code>str</code> <p>The type of artifact to load.</p> required <code>artifact_name</code> <code>str</code> <p>The base name of the artifact.</p> required <code>artifact_alias</code> <code>str</code> <p>The alias of the artifact.</p> required <code>per_page</code> <code>int</code> <p>Number of items to retrieve per page. Defaults to 100.</p> <code>100</code> <p>Returns:</p> Type Description <code>Union[Artifact, None]</code> <p>wandb.Artifact: The loaded WandB artifact or None if it doesn't exist.</p> Source code in <code>aimet_ml/utils/wandb_utils.py</code> <pre><code>def load_artifact(\n    api: wandb.Api, artifact_type: str, artifact_name: str, artifact_alias: str, per_page: int = 100\n) -&gt; Union[wandb.Artifact, None]:\n    \"\"\"\n    Load a WandB artifact by name and alias.\n\n    Args:\n        api (wandb.Api): The WandB API client.\n        artifact_type (str): The type of artifact to load.\n        artifact_name (str): The base name of the artifact.\n        artifact_alias (str): The alias of the artifact.\n        per_page (int, optional): Number of items to retrieve per page. Defaults to 100.\n\n    Returns:\n        wandb.Artifact: The loaded WandB artifact or None if it doesn't exist.\n    \"\"\"\n    available_artifact_types = [t.name for t in api.artifact_types()]\n    if artifact_type not in available_artifact_types:\n        return None\n\n    available_artifact_names = list_artifact_names(api, artifact_type, per_page=per_page)\n\n    artifact_name_with_alias = f\"{artifact_name}:{artifact_alias}\"\n\n    if artifact_name_with_alias not in available_artifact_names:\n        return None\n\n    return wandb.use_artifact(artifact_name_with_alias)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.wandb_utils.table_to_dataframe","title":"<code>table_to_dataframe(table)</code>","text":"<p>Convert a WandB table to a Pandas DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>Table</code> <p>The WandB table to be converted.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>pd.DataFrame: A Pandas DataFrame containing the data from the WandB table.</p> Source code in <code>aimet_ml/utils/wandb_utils.py</code> <pre><code>def table_to_dataframe(table: wandb.Table) -&gt; pd.DataFrame:\n    \"\"\"\n    Convert a WandB table to a Pandas DataFrame.\n\n    Args:\n        table (wandb.Table): The WandB table to be converted.\n\n    Returns:\n        pd.DataFrame: A Pandas DataFrame containing the data from the WandB table.\n    \"\"\"\n    return pd.DataFrame(data=table.data, columns=table.columns)\n</code></pre>"}]}