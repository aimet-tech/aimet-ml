{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#aimet-ml","title":"aimet-ml","text":"<p>Python package of frequently used modules for ML developments in AIMET.</p> <ul> <li>Documentation: https://aimet-tech.github.io/aimet-ml</li> <li>GitHub: https://github.com/aimet-tech/aimet-ml</li> <li>PyPI: https://pypi.org/project/aimet-ml/</li> <li>Free software: MIT</li> </ul>"},{"location":"#features","title":"Features","text":"<ul> <li>TODO</li> </ul>"},{"location":"#credits","title":"Credits","text":"<p>This package was created with Cookiecutter and the waynerv/cookiecutter-pypackage project template.</p>"},{"location":"changelog/","title":"Changelog","text":""},{"location":"changelog/#changelog","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is based on Keep a Changelog, and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#020---2023-08-28","title":"[0.2.0] - 2023-08-28","text":""},{"location":"changelog/#added","title":"Added","text":"<ul> <li>Change layout of module document</li> </ul>"},{"location":"changelog/#011---2023-08-26","title":"[0.1.1] - 2023-08-26","text":""},{"location":"changelog/#added_1","title":"Added","text":"<ul> <li>Cover tests for more modules</li> </ul>"},{"location":"changelog/#010---2023-08-26","title":"[0.1.0] - 2023-08-26","text":""},{"location":"changelog/#added_2","title":"Added","text":"<ul> <li>First release (pre-release) on PyPI.</li> </ul>"},{"location":"contributing/","title":"Contributing","text":""},{"location":"contributing/#contributing","title":"Contributing","text":"<p>Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.</p> <p>You can contribute in many ways:</p>"},{"location":"contributing/#types-of-contributions","title":"Types of Contributions","text":""},{"location":"contributing/#report-bugs","title":"Report Bugs","text":"<p>Report bugs at https://github.com/aimet-tech/aimet-ml/issues.</p> <p>If you are reporting a bug, please include:</p> <ul> <li>Your operating system name and version.</li> <li>Any details about your local setup that might be helpful in troubleshooting.</li> <li>Detailed steps to reproduce the bug.</li> </ul>"},{"location":"contributing/#fix-bugs","title":"Fix Bugs","text":"<p>Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#implement-features","title":"Implement Features","text":"<p>Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.</p>"},{"location":"contributing/#write-documentation","title":"Write Documentation","text":"<p>aimet-ml could always use more documentation, whether as part of the official aimet-ml docs, in docstrings, or even on the web in blog posts, articles, and such.</p>"},{"location":"contributing/#submit-feedback","title":"Submit Feedback","text":"<p>The best way to send feedback is to file an issue at https://github.com/aimet-tech/aimet-ml/issues.</p> <p>If you are proposing a feature:</p> <ul> <li>Explain in detail how it would work.</li> <li>Keep the scope as narrow as possible, to make it easier to implement.</li> <li>Remember that this is a volunteer-driven project, and that contributions   are welcome :)</li> </ul>"},{"location":"contributing/#get-started","title":"Get Started!","text":"<p>Ready to contribute? Here's how to set up <code>aimet-ml</code> for local development.</p> <ol> <li>Fork the <code>aimet-ml</code> repo on GitHub.</li> <li> <p>Clone your fork locally</p> <pre><code>$ git clone git@github.com:your_name_here/aimet-ml.git\n</code></pre> </li> <li> <p>Ensure poetry is installed.</p> </li> <li> <p>Install dependencies and start your virtualenv:</p> <pre><code>$ poetry install -E test -E doc -E dev\n</code></pre> </li> <li> <p>Create a branch for local development:</p> <pre><code>$ git checkout -b name-of-your-bugfix-or-feature\n</code></pre> <p>Now you can make your changes locally.</p> </li> <li> <p>When you're done making changes, check that your changes pass the    tests, including testing other Python versions, with tox:</p> <pre><code>$ poetry run tox\n</code></pre> </li> <li> <p>Commit your changes and push your branch to GitHub:</p> <pre><code>$ git add .\n$ git commit -m \"Your detailed description of your changes.\"\n$ git push origin name-of-your-bugfix-or-feature\n</code></pre> </li> <li> <p>Submit a pull request through the GitHub website.</p> </li> </ol>"},{"location":"contributing/#pull-request-guidelines","title":"Pull Request Guidelines","text":"<p>Before you submit a pull request, check that it meets these guidelines:</p> <ol> <li>The pull request should include tests.</li> <li>If the pull request adds functionality, the docs should be updated. Put    your new functionality into a function with a docstring, and add the    feature to the list in README.md.</li> <li>The pull request should work for Python 3.6, 3.7, 3.8 and 3.9. Check    https://github.com/aimet-tech/aimet-ml/actions    and make sure that the tests pass for all supported Python versions.</li> </ol>"},{"location":"contributing/#tips","title":"Tips","text":"<pre><code>$ poetry run pytest tests/test_aimet_ml.py\n</code></pre> <p>To run a subset of tests.</p>"},{"location":"contributing/#deploying","title":"Deploying","text":"<p>A reminder for the maintainers on how to deploy. Make sure all your changes are committed (including an entry in CHANGELOG.md). Then run:</p> <pre><code>$ poetry run bump2version patch # possible: major / minor / patch\n$ git push\n$ git push --tags\n</code></pre> <p>GitHub Actions will then deploy to PyPI if tests pass.</p>"},{"location":"installation/","title":"Installation","text":""},{"location":"installation/#installation","title":"Installation","text":""},{"location":"installation/#stable-release","title":"Stable release","text":"<p>To install aimet-ml, run this command in your terminal:</p> <pre><code>$ pip install aimet-ml\n</code></pre> <p>This is the preferred method to install aimet-ml, as it will always install the most recent stable release.</p> <p>If you don't have pip installed, this Python installation guide can guide you through the process.</p>"},{"location":"installation/#from-source","title":"From source","text":"<p>The source for aimet-ml can be downloaded from the Github repo.</p> <p>You can either clone the public repository:</p> <pre><code>$ git clone git://github.com/aimet-tech/aimet-ml\n</code></pre> <p>Or download the tarball:</p> <pre><code>$ curl -OJL https://github.com/aimet-tech/aimet-ml/tarball/main\n</code></pre> <p>Once you have a copy of the source, you can install it with:</p> <pre><code>$ pip install .\n</code></pre>"},{"location":"usage/","title":"Usage","text":""},{"location":"usage/#usage","title":"Usage","text":"<p>To use aimet-ml in a project</p> <pre><code>import aimet_ml\n</code></pre>"},{"location":"api/features/","title":"features","text":""},{"location":"api/features/#aimet_ml.features.textual","title":"<code>textual</code>","text":""},{"location":"api/features/#aimet_ml.features.textual.transformers","title":"<code>transformers</code>","text":""},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor","title":"<code>TransformerFeatureExtractor</code>","text":"<p>Extracts features from input texts using transformer embeddings.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>class TransformerFeatureExtractor:\n\"\"\"Extracts features from input texts using transformer embeddings.\"\"\"\n\n    def __init__(\n        self,\n        model_name: str,\n        num_emb_layers: int = 4,\n        max_length: int = 512,\n        device: Union[str, torch.device] = \"cuda:0\",\n    ):\n\"\"\"\n        Initializes the TransformerFeatureExtractor.\n\n        Args:\n            model_name (str): The name or path of the pre-trained transformer model.\n            num_emb_layers (int, optional): Number of layers to use for feature extraction. Default is 4.\n            max_length (int, optional): Maximum length of input text for tokenization. Default is 512.\n            device (str or torch.device, optional): Device to use for computation ('cuda:0', 'cpu', etc.).\n                Default is 'cuda:0' if available, else 'cpu'.\n        \"\"\"\n\n        if not torch.cuda.is_available():\n            device = \"cpu\"\n\n        self.model = AutoModel.from_pretrained(model_name)\n        self.model.to(device)\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n        self.num_emb_layers = num_emb_layers\n        self.max_length = max_length\n\n    def extract_features(self, texts: Union[str, List[str]]) -&gt; torch.Tensor:\n\"\"\"\n        Extracts features from input texts using transformer embeddings.\n\n        Args:\n            texts (str or list): Input text or list of texts for feature extraction.\n\n        Returns:\n            torch.Tensor: Extracted features for input texts.\n        \"\"\"\n        self.model.eval()\n\n        if isinstance(texts, str):\n            texts = [texts]\n\n        input_ids, attention_masks = [], []\n        for text in texts:\n            tokenized_output = self.tokenize(text)\n            input_ids.append(tokenized_output[\"input_ids\"])\n            attention_masks.append(tokenized_output[\"attention_mask\"])\n        input_ids_tensor = torch.cat(input_ids, dim=0).to(self.model.device)\n        attention_masks_tensor = torch.cat(attention_masks, dim=0).to(self.model.device)\n\n        with torch.no_grad():\n            hidden_states = self.model(\n                input_ids_tensor, attention_mask=attention_masks_tensor, output_hidden_states=True\n            )[\"hidden_states\"]\n\n        embeddings = sum(hidden_states[-i][:, 0, :] for i in range(1, self.num_emb_layers + 1))\n        embeddings = embeddings.detach().cpu()\n\n        return embeddings\n\n    def tokenize(self, text: str) -&gt; dict:\n\"\"\"\n        Tokenizes input text using the transformer's tokenizer.\n\n        Args:\n            text (str): Input text to be tokenized.\n\n        Returns:\n            dict: Dictionary containing tokenized input with attention mask.\n        \"\"\"\n        tokenized_output = self.tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=self.max_length,\n            padding=\"max_length\",\n            truncation=True,\n            return_attention_mask=True,\n            return_tensors=\"pt\",\n        )\n\n        return tokenized_output.data\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.__init__","title":"<code>__init__(model_name, num_emb_layers=4, max_length=512, device='cuda:0')</code>","text":"<p>Initializes the TransformerFeatureExtractor.</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>The name or path of the pre-trained transformer model.</p> required <code>num_emb_layers</code> <code>int</code> <p>Number of layers to use for feature extraction. Default is 4.</p> <code>4</code> <code>max_length</code> <code>int</code> <p>Maximum length of input text for tokenization. Default is 512.</p> <code>512</code> <code>device</code> <code>str or device</code> <p>Device to use for computation ('cuda:0', 'cpu', etc.). Default is 'cuda:0' if available, else 'cpu'.</p> <code>'cuda:0'</code> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def __init__(\n    self,\n    model_name: str,\n    num_emb_layers: int = 4,\n    max_length: int = 512,\n    device: Union[str, torch.device] = \"cuda:0\",\n):\n\"\"\"\n    Initializes the TransformerFeatureExtractor.\n\n    Args:\n        model_name (str): The name or path of the pre-trained transformer model.\n        num_emb_layers (int, optional): Number of layers to use for feature extraction. Default is 4.\n        max_length (int, optional): Maximum length of input text for tokenization. Default is 512.\n        device (str or torch.device, optional): Device to use for computation ('cuda:0', 'cpu', etc.).\n            Default is 'cuda:0' if available, else 'cpu'.\n    \"\"\"\n\n    if not torch.cuda.is_available():\n        device = \"cpu\"\n\n    self.model = AutoModel.from_pretrained(model_name)\n    self.model.to(device)\n\n    self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n    self.num_emb_layers = num_emb_layers\n    self.max_length = max_length\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.extract_features","title":"<code>extract_features(texts)</code>","text":"<p>Extracts features from input texts using transformer embeddings.</p> <p>Parameters:</p> Name Type Description Default <code>texts</code> <code>str or list</code> <p>Input text or list of texts for feature extraction.</p> required <p>Returns:</p> Type Description <code>Tensor</code> <p>torch.Tensor: Extracted features for input texts.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def extract_features(self, texts: Union[str, List[str]]) -&gt; torch.Tensor:\n\"\"\"\n    Extracts features from input texts using transformer embeddings.\n\n    Args:\n        texts (str or list): Input text or list of texts for feature extraction.\n\n    Returns:\n        torch.Tensor: Extracted features for input texts.\n    \"\"\"\n    self.model.eval()\n\n    if isinstance(texts, str):\n        texts = [texts]\n\n    input_ids, attention_masks = [], []\n    for text in texts:\n        tokenized_output = self.tokenize(text)\n        input_ids.append(tokenized_output[\"input_ids\"])\n        attention_masks.append(tokenized_output[\"attention_mask\"])\n    input_ids_tensor = torch.cat(input_ids, dim=0).to(self.model.device)\n    attention_masks_tensor = torch.cat(attention_masks, dim=0).to(self.model.device)\n\n    with torch.no_grad():\n        hidden_states = self.model(\n            input_ids_tensor, attention_mask=attention_masks_tensor, output_hidden_states=True\n        )[\"hidden_states\"]\n\n    embeddings = sum(hidden_states[-i][:, 0, :] for i in range(1, self.num_emb_layers + 1))\n    embeddings = embeddings.detach().cpu()\n\n    return embeddings\n</code></pre>"},{"location":"api/features/#aimet_ml.features.textual.transformers.TransformerFeatureExtractor.tokenize","title":"<code>tokenize(text)</code>","text":"<p>Tokenizes input text using the transformer's tokenizer.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>Input text to be tokenized.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>Dictionary containing tokenized input with attention mask.</p> Source code in <code>aimet_ml/features/textual/transformers.py</code> <pre><code>def tokenize(self, text: str) -&gt; dict:\n\"\"\"\n    Tokenizes input text using the transformer's tokenizer.\n\n    Args:\n        text (str): Input text to be tokenized.\n\n    Returns:\n        dict: Dictionary containing tokenized input with attention mask.\n    \"\"\"\n    tokenized_output = self.tokenizer.encode_plus(\n        text,\n        add_special_tokens=True,\n        max_length=self.max_length,\n        padding=\"max_length\",\n        truncation=True,\n        return_attention_mask=True,\n        return_tensors=\"pt\",\n    )\n\n    return tokenized_output.data\n</code></pre>"},{"location":"api/processing/","title":"processing","text":""},{"location":"api/processing/#aimet_ml.processing.audio","title":"<code>audio</code>","text":""},{"location":"api/processing/#aimet_ml.processing.audio.convert_audio","title":"<code>convert_audio(src_file, dst_file, target_sr=None, normalize=False)</code>","text":"<p>Convert an audio file to a different sample rate and save it to a new file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>str</code> <p>Path to the source audio file.</p> required <code>dst_file</code> <code>str</code> <p>Path to the destination audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the output audio file.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform before conversion.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>AudioSegment</code> <code>AudioSegment</code> <p>The converted audio waveform as an AudioSegment object.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def convert_audio(\n    src_file: str, dst_file: str, target_sr: Optional[int] = None, normalize: bool = False\n) -&gt; AudioSegment:\n\"\"\"\n    Convert an audio file to a different sample rate and save it to a new file.\n\n    Args:\n        src_file (str): Path to the source audio file.\n        dst_file (str): Path to the destination audio file.\n        target_sr (int, optional): Target sample rate for the output audio file.\n        normalize (bool, optional): If True, normalize the audio waveform before conversion.\n\n    Returns:\n        AudioSegment: The converted audio waveform as an AudioSegment object.\n    \"\"\"\n    audio = read_audio(src_file, target_sr, normalize)\n    output_format = dst_file.split(\".\")[-1]\n    audio.export(dst_file, format=output_format)\n    return audio\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.audio.load_audio","title":"<code>load_audio(file_path, target_sr=None, normalize=False)</code>","text":"<p>Load an audio file and return the waveform as a NumPy array and the target sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the audio waveform.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform.</p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[ndarray, int]</code> <p>Tuple[np.ndarray, int]: A tuple containing the waveform as a NumPy array and the target sample rate.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def load_audio(file_path: str, target_sr: Optional[int] = None, normalize: bool = False) -&gt; Tuple[np.ndarray, int]:\n\"\"\"\n    Load an audio file and return the waveform as a NumPy array and the target sample rate.\n\n    Args:\n        file_path (str): Path to the audio file.\n        target_sr (int, optional): Target sample rate for the audio waveform.\n        normalize (bool, optional): If True, normalize the audio waveform.\n\n    Returns:\n        Tuple[np.ndarray, int]: A tuple containing the waveform as a NumPy array and the target sample rate.\n    \"\"\"\n    audio = read_audio(file_path, target_sr, normalize)\n    waveform = np.asarray(audio.get_array_of_samples(), dtype=np.float32) / 32768.0\n    sample_rate = audio.frame_rate\n    return waveform, sample_rate\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.audio.read_audio","title":"<code>read_audio(file_path, target_sr=None, normalize=False)</code>","text":"<p>Read an audio file and return the waveform as an AudioSegment object with the target sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>Path to the audio file.</p> required <code>target_sr</code> <code>int</code> <p>Target sample rate for the audio waveform.</p> <code>None</code> <code>normalize</code> <code>bool</code> <p>If True, normalize the audio waveform.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>AudioSegment</code> <code>AudioSegment</code> <p>Audio waveform as an AudioSegment object.</p> Source code in <code>aimet_ml/processing/audio.py</code> <pre><code>def read_audio(file_path: str, target_sr: Optional[int] = None, normalize: bool = False) -&gt; AudioSegment:\n\"\"\"\n    Read an audio file and return the waveform as an AudioSegment object with the target sample rate.\n\n    Args:\n        file_path (str): Path to the audio file.\n        target_sr (int, optional): Target sample rate for the audio waveform.\n        normalize (bool, optional): If True, normalize the audio waveform.\n\n    Returns:\n        AudioSegment: Audio waveform as an AudioSegment object.\n    \"\"\"\n    audio = AudioSegment.from_file(file_path)\n    if target_sr:\n        audio = audio.set_frame_rate(target_sr)\n    if normalize:\n        audio = effects.normalize(audio)\n    return audio\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text","title":"<code>text</code>","text":""},{"location":"api/processing/#aimet_ml.processing.text.clean_repeated_tokens","title":"<code>clean_repeated_tokens(tokens)</code>","text":"<p>Remove sequences of repeated tokens from a list.</p> <p>Parameters:</p> Name Type Description Default <code>tokens</code> <code>list[str]</code> <p>List of tokens to clean.</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>list[str]: List of tokens with repeated sequences removed.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def clean_repeated_tokens(tokens: List[str]) -&gt; List[str]:\n\"\"\"\n    Remove sequences of repeated tokens from a list.\n\n    Args:\n        tokens (list[str]): List of tokens to clean.\n\n    Returns:\n        list[str]: List of tokens with repeated sequences removed.\n    \"\"\"\n    tokens = tokens.copy()\n    sequence_size = len(tokens) // 2\n    while sequence_size &gt; 0:\n        cur_idx = 0\n        while cur_idx &lt; len(tokens) - sequence_size:\n            next_idx = cur_idx + sequence_size\n            cur_text = \"\".join(tokens[cur_idx : cur_idx + sequence_size])\n            next_text = \"\".join(tokens[next_idx : next_idx + sequence_size])\n            if cur_text == next_text:\n                tokens = tokens[: cur_idx + sequence_size] + tokens[next_idx + sequence_size :]\n            else:\n                cur_idx += 1\n        sequence_size -= 1\n    return tokens\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text.exclude_keywords","title":"<code>exclude_keywords(text, keywords)</code>","text":"<p>Check if any of the given keywords are present in the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to search for keywords.</p> required <code>keywords</code> <code>list[str]</code> <p>List of keywords to check for.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>False if any keyword is present in the text, True otherwise.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def exclude_keywords(text: str, keywords: List[str]) -&gt; bool:\n\"\"\"\n    Check if any of the given keywords are present in the text.\n\n    Args:\n        text (str): The text to search for keywords.\n        keywords (list[str]): List of keywords to check for.\n\n    Returns:\n        bool: False if any keyword is present in the text, True otherwise.\n    \"\"\"\n    for kw in keywords:\n        if kw in text:\n            return False\n    return True\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.text.include_keywords","title":"<code>include_keywords(text, keywords)</code>","text":"<p>Check if any of the given keywords are present in the text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The text to search for keywords.</p> required <code>keywords</code> <code>list[str]</code> <p>List of keywords to check for.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if any keyword is present in the text, False otherwise.</p> Source code in <code>aimet_ml/processing/text.py</code> <pre><code>def include_keywords(text: str, keywords: List[str]) -&gt; bool:\n\"\"\"\n    Check if any of the given keywords are present in the text.\n\n    Args:\n        text (str): The text to search for keywords.\n        keywords (list[str]): List of keywords to check for.\n\n    Returns:\n        bool: True if any keyword is present in the text, False otherwise.\n    \"\"\"\n    for kw in keywords:\n        if kw in text:\n            return True\n    return False\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video","title":"<code>video</code>","text":""},{"location":"api/processing/#aimet_ml.processing.video.convert_video","title":"<code>convert_video(src_file, dst_file, target_fps)</code>","text":"<p>Convert a video to a different frame rate and save to a new file.</p> <p>Parameters:</p> Name Type Description Default <code>src_file</code> <code>str</code> <p>Path to the source video file.</p> required <code>dst_file</code> <code>str</code> <p>Path to the output video file.</p> required <code>target_fps</code> <code>int</code> <p>The target frames per second for the output video.</p> required Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def convert_video(src_file: str, dst_file: str, target_fps: int) -&gt; None:\n\"\"\"\n    Convert a video to a different frame rate and save to a new file.\n\n    Args:\n        src_file (str): Path to the source video file.\n        dst_file (str): Path to the output video file.\n        target_fps (int): The target frames per second for the output video.\n    \"\"\"\n    input_vid = ffmpeg.input(src_file)\n\n    audio = input_vid.audio\n    video = input_vid.video.filter(\"fps\", target_fps)\n    (\n        ffmpeg.output(\n            video,\n            audio,\n            dst_file,\n            acodec=\"aac\",\n            loglevel=\"quiet\",\n            max_muxing_queue_size=1024,\n        )\n        .overwrite_output()\n        .run()\n    )\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video.is_video","title":"<code>is_video(file_path)</code>","text":"<p>Check if a given file contains video streams.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the input file.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the file contains video streams, False otherwise.</p> Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def is_video(file_path: str) -&gt; bool:\n\"\"\"\n    Check if a given file contains video streams.\n\n    Args:\n        file_path (str): The path to the input file.\n\n    Returns:\n        bool: True if the file contains video streams, False otherwise.\n    \"\"\"\n    probe = ffmpeg.probe(file_path)\n    streams = probe[\"streams\"]\n\n    for stream in streams:\n        if stream[\"codec_type\"] == \"video\":\n            return True\n\n    return False\n</code></pre>"},{"location":"api/processing/#aimet_ml.processing.video.load_video","title":"<code>load_video(file_path)</code>","text":"<p>Load frames from a video file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path to the video file.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <code>tuple</code> <p>A tuple containing a list of frames and the frames per second (fps).</p> Source code in <code>aimet_ml/processing/video.py</code> <pre><code>def load_video(file_path: str) -&gt; tuple:\n\"\"\"\n    Load frames from a video file.\n\n    Args:\n        file_path (str): The path to the video file.\n\n    Returns:\n        tuple: A tuple containing a list of frames and the frames per second (fps).\n    \"\"\"\n    frames: List[np.ndarray] = []\n    cap = cv2.VideoCapture(file_path)\n    fps = cap.get(cv2.CAP_PROP_FPS)\n\n    while True:\n        ret, frame = cap.read()\n        if not ret:\n            break\n        frames.append(frame)\n\n    cap.release()\n    return frames, fps\n</code></pre>"},{"location":"api/utils/","title":"utils","text":""},{"location":"api/utils/#aimet_ml.utils.hamd_7","title":"<code>hamd_7</code>","text":""},{"location":"api/utils/#aimet_ml.utils.hamd_7.score_to_severity","title":"<code>score_to_severity(score)</code>","text":"<p>Convert a score to a severity category.</p> <p>Parameters:</p> Name Type Description Default <code>score</code> <code>int</code> <p>The input score.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The corresponding severity category (\"normal\", \"mild\", \"moderate\", or \"severe\").</p> Source code in <code>aimet_ml/utils/hamd_7.py</code> <pre><code>def score_to_severity(score: int) -&gt; str:\n\"\"\"\n    Convert a score to a severity category.\n\n    Args:\n        score (int): The input score.\n\n    Returns:\n        str: The corresponding severity category (\"normal\", \"mild\", \"moderate\", or \"severe\").\n    \"\"\"\n    if score &lt; 5:\n        return \"normal\"\n    if score &lt; 13:\n        return \"mild\"\n    if score &lt; 21:\n        return \"moderate\"\n    return \"severe\"\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots","title":"<code>plots</code>","text":""},{"location":"api/utils/#aimet_ml.utils.plots.add_bar_label","title":"<code>add_bar_label(bar_chart, with_percent=False, percent_digits=2)</code>","text":"<p>Add labels to a bar chart with optional percentage values.</p> <p>Parameters:</p> Name Type Description Default <code>bar_chart</code> <code>bar</code> <p>The bar chart object.</p> required <code>with_percent</code> <code>bool</code> <p>Whether to include percentage values. Defaults to False.</p> <code>False</code> <code>percent_digits</code> <code>int</code> <p>Number of decimal digits for percentage values. Defaults to 2.</p> <code>2</code> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def add_bar_label(bar_chart: plt.bar, with_percent: bool = False, percent_digits: int = 2) -&gt; None:\n\"\"\"\n    Add labels to a bar chart with optional percentage values.\n\n    Args:\n        bar_chart (plt.bar): The bar chart object.\n        with_percent (bool, optional): Whether to include percentage values. Defaults to False.\n        percent_digits (int, optional): Number of decimal digits for percentage values. Defaults to 2.\n    \"\"\"\n    containers = bar_chart.containers[0]\n    labels = None\n    if with_percent:\n        datavalues = containers.datavalues\n        total = sum(datavalues)\n        labels = [f\"{v:,} ({v/total*100:.{percent_digits}f}%)\" for v in datavalues]\n    bar_chart.bar_label(containers, labels)\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.plt2arr","title":"<code>plt2arr(fig, draw=True)</code>","text":"<p>Convert a Matplotlib figure to a NumPy array.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure</code> <p>The Matplotlib figure to be converted.</p> required <code>draw</code> <code>bool</code> <p>Whether to draw the figure. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The converted figure as a NumPy array.</p> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def plt2arr(fig: Figure, draw: bool = True) -&gt; np.ndarray:\n\"\"\"\n    Convert a Matplotlib figure to a NumPy array.\n\n    Args:\n        fig (Figure): The Matplotlib figure to be converted.\n        draw (bool, optional): Whether to draw the figure. Defaults to True.\n\n    Returns:\n        np.ndarray: The converted figure as a NumPy array.\n    \"\"\"\n    if draw:\n        fig.canvas.draw()\n    rgba_buf = fig.canvas.buffer_rgba()\n    (w, h) = fig.canvas.get_width_height()\n    rgba_arr = np.frombuffer(rgba_buf, dtype=np.uint8).reshape((h, w, 4))\n    return rgba_arr\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.set_font","title":"<code>set_font(font_path)</code>","text":"<p>Set the font for Matplotlib using the provided font file.</p> <p>Parameters:</p> Name Type Description Default <code>font_path</code> <code>str</code> <p>Path to the font file.</p> required Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def set_font(font_path: str) -&gt; None:\n\"\"\"\n    Set the font for Matplotlib using the provided font file.\n\n    Args:\n        font_path (str): Path to the font file.\n    \"\"\"\n    import matplotlib\n    import matplotlib.font_manager\n\n    font_prop = matplotlib.font_manager.FontProperties(fname=font_path)\n    matplotlib.font_manager.fontManager.addfont(font_path)\n    matplotlib.rc(\"font\", family=font_prop.get_name())\n</code></pre>"},{"location":"api/utils/#aimet_ml.utils.plots.set_thai_font","title":"<code>set_thai_font()</code>","text":"<p>Set the Thai font for Matplotlib using a predefined font path.</p> Source code in <code>aimet_ml/utils/plots.py</code> <pre><code>def set_thai_font() -&gt; None:\n\"\"\"Set the Thai font for Matplotlib using a predefined font path.\"\"\"\n    font_path = str(PWD.parent / \"resources\" / \"fonts\" / \"thsarabunnew-webfont.ttf\")\n    set_font(font_path)\n</code></pre>"}]}